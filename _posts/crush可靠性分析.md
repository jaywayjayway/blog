title: crush设计之可靠性分析
date: 2017-03-16 08:44:10
tags:
 - crush
categories: ceph

---

## 前言

数据的可靠性是所有存储系统的首要指标，本文将通过ceph与一致性hash的对比，以及从crush层面的定量分析，展示ceph在数据可靠性方面的特点。

## 一致性hash

一致性hash算根据一个叫一致性hash环的数据结构来实现`key`到存储节点的映射（如图一所示）。
<center>![哈希环](http://i.imgur.com/aKImmF5.png)</center>
<center>图一</center>



算法过程如下：首先会构造一个长度为0~2^32-1的整数空间，然后首尾相连，形成一个封闭的环。根据存储节点的名称经过hash处理，取得一个值（其值也在封闭环范围内），然后把存储节点按这个值映射到哈希环上（如图一中的`node0`,`node1`,`node2`）。


假设数据为x(如图一中的`key0~key4`)，存储节点数目为N(图一所示为`3`）。将数据分布到存储节点的最直接做法是，计算数据x的Hash值，hash值落在哪个区间内（如图一中的`key0`落在[node2,node0],`key2`落在[node0,node1])，就把这个 `x` 存入相应的存储节点中。

**注意**
> [node2,node0]空间实际可划分为[node2,2^32-1]和[0,node0] 


当有新的存储节点添加与删除时，一致性hash算法 （相较传统的取余算法） 并不会引起全局数据的迁移，只会涉及到部分数据转移，这对全局影响相对较小。如下图二展示
<center>![addnode](http://i.imgur.com/g7tqGuS.png))</center>
<center>图二</center>


当加入新节点时（如图二中的`node3`),原本[node2,node0]的存储空间被划分成[node2,node3],[node3,node2]两个区域，原来映射到`node0`的key4,映射到了新的存储节点上（node3），而其他的数据（如图二中的`key0`,`key1`,`key2`,`key3`)并不会引起数据迁移。


当有节点被剔除时（如图三所示的`node2`），其所存储的`key4`会被重新映射[node1,node0]区域，存储到`node0`节点上,其他数据也不会变更。
<center>![deletenode](http://i.imgur.com/zPrANm7.png)</center>
<center>图三</center>



但一致性Hash的一个问题是，存储节点不能将Hash空间均匀划分。如图三所示，[node1,node0]的空间的比[node0,node1]大得多，这容易让负责该分区的节点node0负载过重。假设2个节点的磁盘容量相等，那么当节点node0的存储空间满载时，node1的磁盘还有很大的空闲空间，但此时系统已经无法继续向[node1, node0]空音写入数据，从而造成资源浪费。

- **虚拟节点**

计算机界有句名言： **计算机的任何问题都可以通过增加一个虚拟层来解决** ，在计算机硬件、计算机网络、计算机软件概莫如此。为解决一致性hash算法带来的资源使用分配不均匀的问题，也可以引入 *虚拟化* 的手段。虚拟节点是相对于物理存储节点而言的，虚拟节点负责的分区上的数据最终存储到其对应的物理节点。一台物理节点可以虚拟出一个或多个虚拟节点（如图四，每个物理节点只虚拟一个）。新的空间为`[v0,v1]`,`[v1,v2]`,`[v2,v0]`，分别映射到`node0`,`node1`,`node2`物理存储节点。如此一来，三个物理节点的数据承载趋于均匀。

<center>![](http://i.imgur.com/fheaAvg.png)</center>
<center>图四</center>

实际应用中，可以根据物理节点的磁盘容量的大小来确定其对应的虚拟节点数目。虚拟节点数目越多，节点负责的数据区间也越大。

- **CRUSH算法**

ceph的数据分布流程如图五所示：

<center>![pgmap](http://i.imgur.com/Md9PN4i.png)</center>
<center>图五</center>

整个流程为：
> - 1. 取得object的name进行hash运算
> - 2. 取得的hash值与 PG 数取余，得到的结果与`pool ID` 结成PG的编号 （如图五中的4.32)
> - 3. 通过crsuh算法，把PG映射到具体的OSD 

在Ceph里，`PG`是数据存储的管理单元，如果把PG当作一致性hasn里的存储节点，那么它就是最简单数据分布（即取余算法）方式。不同的是，PG是抽象的存储节点，它不会随着物理节点的加入或则离开而增加或减少，因此数据到PG的映射是稳定的。
<center>![pghash](http://i.imgur.com/oD3dNV4.png)</center>
<center>图六</center>

当在ceph里创建 存储池（指定 `pg `的数量），整个  `hash` 环就固定了（如图六所示），对象到PG的映射就唯一确认，即数据具体存储到哪个PG是确定的，不会随便着下层OSD的增删而改变，这充分体现了ceph在数据可靠性的特征之一。

**注意**
> 在实际环境中，切勿随便变更pool的PG数量，这将引起数据的大规模迁移。









